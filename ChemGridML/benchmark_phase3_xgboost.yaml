# Comprehensive Benchmark - Phase 3: Add XGBoost
# Add XGBoost - gradient boosting, often best performance

data:
  train_csv: "../ExpansionRX_train.csv"
  test_csv: "../ExpansionRX_test.csv"
  smiles_column: "SMILES"

targets:
  - "KSOL"
  - "LogD"
  - "MLM CLint"
  - "HLM CLint"

features:
  - "ECFP"
  - "AtomPair"
  - "MACCS"
  - "RDKitFP"
  - "TOPOTOR"
  - "MOL2VEC"

models:
  - "ElasticNet"
  - "RF"
  - "XGBoost"

experiment:
  name: "OpenADMET_Phase3_XGBoost"
  n_tests: 10
  n_folds: 5
  n_trials: 15
  test_size: 0.2
  
output:
  results_dir: "openadmet_results"
  save_predictions: true
  save_models: false
  
visualization:
  create_plots: true
  plot_types:
    - "performance_comparison"
    - "prediction_scatter"
  figure_format: "png"
  dpi: 300
